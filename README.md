# DADS7202_Group Assignment 1 (Group 2 Coupon)
Which one is better for structured data, traditional ML or MLP?

## ‚ú®Highlight
- Highlight1 ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô / ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö / insight
- Highlight2
- Highlight3
- Highlight4
- Highlight5

## 1.IntroductionüéØ 

Binary classification:

This project aims to train a classification model that can predict if a driver will accept a coupon recommended to his/her in different driving scenariosüöó.

(1: Accept coupons, 0: Deny coupons)

## 2. Dataüìë
#### üìçData source: 
[In-vehicle coupon recommendation Data Set](https://archive.ics.uci.edu/ml/datasets/in-vehicle+coupon+recommendation)

This data was collected via a survey on Amazon Mechanical Turk. The survey describes different driving scenarios including the destination, current time, weather, passenger, etc., and then ask the person whether he will accept the coupon if he is the driver. 

For more information about the dataset, please refer to the paper:
Wang, Tong, Cynthia Rudin, Finale Doshi-Velez, Yimin Liu, Erica Klampfl, and Perry MacNeille. 'A bayesian framework for learning rule sets for interpretable classification.' The Journal of Machine Learning Research 18, no. 1 (2017): 2357-2393.

#### üîéExploratory Data Analysis(EDA): 
##### Data preparation:
##### Data pre-processing:
##### Data post-processing:
#### ‚úÇÔ∏èData splitting (train/val/test):
#### üî®How to solve imbalance data:
_‡∏´‡∏≤‡∏Å‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ö‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô imbalance ‡πÉ‡∏ô‡∏ö‡∏≤‡∏á‡∏Ñ‡∏•‡∏≤‡∏™ ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢ (‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏á‡∏≤‡∏ô classification)_

## 3. Network architectureüì¶

## 4. TrainingüîÆ

## 5. Resultsüìà
_ - ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Train vs Validation (‡πÄ‡∏ä‡πà‡∏ô Loss/Accuracy)
‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏Ñ‡∏ß‡∏£‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö scale ‡∏Ñ‡πà‡∏≤‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏•‡∏∞‡∏î‡∏π underfit / overfit ‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢
 - ‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÄ‡∏™‡∏°‡∏≠‡∏ß‡πà‡∏≤‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ö‡∏ô train set ‡∏´‡∏£‡∏∑‡∏≠ val set ‡∏´‡∏£‡∏∑‡∏≠ test set
 - ‡∏£‡∏∞‡∏ö‡∏∏‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏ß‡πâ‡πÄ‡∏™‡∏°‡∏≠ ‡πÄ‡∏ä‡πà‡∏ô ‚Äú‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á xxx‚Äù ‡∏Å‡πá‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡∏à‡∏≤‡∏Å‡πÑ‡∏´‡∏ô‡∏Å‡∏µ‡πà‡∏Ñ‡πà‡∏≤‡∏ö‡πâ‡∏≤‡∏á‡∏ô‡∏≥‡∏°‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Å‡∏±‡∏ô
 - ‡∏£‡∏∞‡∏ß‡∏±‡∏á‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÉ‡∏î ‡πÜ ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ö‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏°‡∏ï‡πà‡∏≠‡∏Ñ‡∏π‡πà‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ‡πÄ‡∏ä‡πà‡∏ô ‡∏´‡∏≤‡∏Å‡∏à‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö training time ‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏´‡∏ô‡∏°‡∏≤‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏±‡∏ô ‡∏Å‡πá‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏õ‡πá‡∏ô training 
time per one epoch (‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡πÜ epoch), ‡∏´‡∏≤‡∏Å‡∏à‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö inference time per 
one sample ‡∏Å‡πá‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏≤‡∏à‡∏≤‡∏Å test samples ‡∏ä‡∏∏‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡∏ö‡∏ô CPU ‡∏´‡∏£‡∏∑‡∏≠ GPU 
‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô, ‡∏´‡∏≤‡∏Å‡∏à‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ß‡πà‡∏≤ loss ‡∏°‡∏≤‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏±‡∏ô ‡∏Å‡πá‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì 
loss ‡∏™‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô_

## 6. Discussionüí≠

## 7. Conclusionüìä
_‡∏Å‡∏≤‡∏£‡∏≠‡∏†‡∏¥‡∏õ‡∏£‡∏≤‡∏¢‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏• ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Å‡∏±‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å

‡∏°‡∏¥‡πÉ‡∏ä‡πà‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡∏Ç‡πâ‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô general conclusion ‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ ‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡∏∑‡πà‡∏ô ‡πÜ 

‡πÉ‡∏ô‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï ‡∏°‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ã‡πâ‡∏≥‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏î ‡πÜ ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏Ç‡πâ‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß_

## 8. Referencesüåê



## üë• Members, Percent Contribution and Responsibility
|No  |ID                |Name                              |% Contribution |Responsibility                             |
|:---:|:---:             |---                               |:---:            |:---|
|1.  |**`6410422002`**  |Navapol San.                      |   **`25%`**     |**`Explore data`** **`Prepare dataset`** **`Experiment with traditional ML`** **`Experiment with MLP `**  
|2.  |**`6410422003`**  |Pakkawut Kam.                     |   **`25%`**     |**`Explore data`** **`Prepare dataset`** **`Experiment with traditional ML`** **`Experiment with MLP `** |
|3.  |**`6410422024`**  |Supisara Poo.                     |   **`25%`**     |**`Explore data`** **`Prepare dataset`** **`Experiment with MLP `** **`Evaluate and conclude result`**  |
|4.  |**`6410422027`**  |Kantima Tec.                      |   **`25%`**     |**`Explore data`** **`Prepare dataset`** **`Experiment with traditional ML`** **`Evaluate and conclude result`** |


## üñáÔ∏èEnd Credit 
This project is a part of **`DADS7202 Deep Learning`**

Term: 1 Year of education: 2022

üéìMaster of Science Program in **`Data Analytics and Data Science`** (DADS)

üè´National Institute of Development Administration (**`NIDA`**)

<img src="https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&color=525252"/> 
