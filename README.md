# DADS7202_Group Assignment 1 (Group 2 MNLP)
> **`Which one is better for structured data, traditional ML or MLP?`**

<img src="https://github.com/lukplamino/DADS7202_HW01_MNLP_Group/blob/main/images/Screenshot%202022-08-29%20174351.png" alt="drawing" style="width:400px;"/>

## ‚ú®Highlight
- Highlight1 ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô / ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö / insight
- Highlight2
- Highlight3
- Highlight4
- Highlight5

## Table of Contents
[Code.ipynp](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group/blob/main/%5BMNLP_Team%5D_7202_HW1_Final_Version.ipynb)
 - [1. IntroductionüéØ](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#1-introduction)
 - [2. Dataüìë](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#2-data)
 - [3. Network architectureüì¶ and TrainingüîÆ](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#3-network-architecture-and-training)
 - [4. Resultsüìà](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#4-results)
 - [5. Discussionüí≠](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#5-discussion)
 - [6. Conclusionüìä](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#6-conclusion)
 - [7. Referencesüåê](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#7-references)
 - [Citing](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#citing)
 - [üë• Members, Percent Contribution and Responsibility](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#-members-percent-contribution-and-responsibility)
 - [üñáÔ∏èEnd Credit ](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#%EF%B8%8Fend-credit)


## 1. IntroductionüéØ 

**`Binary classification`**:

This project aims to compare performance of **`traditional ML models`** and  a **`self-designed MLP network model`** by training  models that can predict if a driver will accept a coupon recommended to his/her in different driving scenariosüöó. (1: Accept coupons, 0: Deny coupons)

## 2. Dataüìë
#### üìçData source: 
[In-vehicle coupon recommendation Data Set](https://archive.ics.uci.edu/ml/datasets/in-vehicle+coupon+recommendation)

This data was collected via a survey on Amazon Mechanical Turk. The survey describes different driving scenarios including the destination, current time, weather, passenger, etc., and then ask the person whether he will accept the coupon if he is the driver. 

For more information about the dataset, please refer to the paper:
Wang, Tong, Cynthia Rudin, Finale Doshi-Velez, Yimin Liu, Erica Klampfl, and Perry MacNeille. 'A bayesian framework for learning rule sets for interpretable classification.' The Journal of Machine Learning Research 18, no. 1 (2017): 2357-2393.

#### üîéExploratory Data Analysis(EDA): 

#### Data preparation and pre-processing:
To get data ready for model:
 - We managed the difference types of data by converting nominal data into object and ordinal data into integer with order from smallest (0) to greatest.
 - We dealt with missing value by 1) drop the column (`car`) since only 1% data available and 2) drop NULL in the residual features because about 1% is missing and distribution does not change after drop out  
 - Lastly, (`Direction_same`) removed as it shares the same information with (`direction_opp`) column

#### üî®How to solve imbalance data:
We found some features experience imbalance problem since it is dominated by only one class (`toCoupon_GEQ5min`: All '1') or one of the class contributes to over 80% (`toCoupon_GEQ25min`)
Consequently, we drop those columns out. And responsible result ('Y') seems be fine without imbalance (60/40)

All in all, data set is ...
**Devide `21 Attributes` into 3 groups** 

**Group I. Persona attributes**

 1. **`Age`**: (<21, 21-25, 26-30, 31-35, 36-40, 41-45, 46-50, >50)
 2. **`Gender`**: (Female, Male)
 3. **`MaritalStatus`**: (Unmarried partner, Single, Married partner, Divorced, Widowed)
 4. **`Has_Children`**: (1: Has, 0: Doesn't have)
 5. **`Education`**:  (Some college - no degree, Bachelors degree, Associates degree, High School Graduate, Graduate degree (Masters or Doctorate), Some High School)\
 6. **`Occupation`**: (Unemployed, Architecture & Engineering, Student,Education&Training&Library, Healthcare Support, Healthcare Practitioners & Technical, Sales & Related, Management, Arts Design,Arts Design Entertainment Sports & Media, Computer & Mathematical, Entertainment Sports & Media, Computer & Mathematical,Life Physical Social Science, Personal Care & Service, Community & Social Services, Office & Administrative Support, Construction & Extraction, Legal, Retired,Installation Maintenance & Repair, Transportation & Material Moving,Business & Financial, Protective Service,Food Preparation & Serving Related, Production Occupations,Building & Grounds Cleaning & Maintenance, Farming Fishing & Forestry)
 7. **`Income`**: ( Less than $12500, $12500 - $24999, $25000 - $37499, $37500 - $49999, $50000 - $62499, $62500 - $74999,  $75000 - $87499, $87500 - $99999, $100000 or More)
 8. **`Bar`**: How many times do you go to a bar every month? (never, less1, 1-3, 4-8, gt8, nan)
 9. **`CoffeeHouse`**: How many times do you go to a coffee house every month? (never, less1, 1-3, 4-8, gt8, nan)
 10. **`CarryAway`**: How many times do you get take-away food every month? (never, less1, 1-3, 4-8, gt8, nan)
 11. **`RestaurantLessThan20`**: How many times do you go to a restaurant with an average expense per person of less than $20 every month? (never, less1, 1-3, 4-8, gt8, nan)
 12. **`Restaurant20To50`**: How many times do you go to a restaurant with average expense per person of $20 - $50 every month? (never, less1, 1-3, 4-8, gt8, nan)


**Group II. Coupon attributes**

 13. **`Coupon`**: The coupon for...(Restaurant(<$20), Restaurant($20-$50, Coffee House, Carry out & Take away, Bar)
 14. **`Expiration`**: The coupon expires in 1 day or in 2 hours (1d, 2h)
 
**Group III. Other attributes**

 15. **`Destination`**: (No Urgent Place, Home, Work)
 16. **`Passanger`**: Who are the passengers in the car? (Alone, Friend(s), Kid(s), Partner)
 17. **`Weather`**: (Sunny, Rainy, Snowy)
 18. **`Temperature`**: (30, 50, 80)
 19. **`Time`**: (7AM, 10AM, 2PM, 6PM, 10PM)
 20. **`toCoupon_GEQ15min`**: Driving distance to the restaurant/bar for using the coupon is greater than 15 minutes (1,0)
 21. **`Direction_same`**: Whether the restaurant/bar is in the same direction as your current destination (1,0)

#### ‚úÇÔ∏èData splitting (train/val/test):
- `random_state` = 88, 
- `test_size` = 0.25
- **`Train Shape`**: (9059, 73)
- **`Test Shape`**: (3020, 73)


[üîù](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#highlight)

## 3. Network architectureüì¶ and TrainingüîÆ
We experiment on each hyperparameter with the following default hyperparameter (change each hyperparameter and keep the default for others) and evaluate the result using **`model accuracy`**  on test set

- **`Random state`**: [88, 99, 100, 110]
- **`Number of Hidden layer`**: min value = 3, max value = 5
- **`Number of Units in Hidden layer`**: [32, 64, 128, 256, 512, 1024]
- **`Activation function in Hidden layer`**: [relu, tanh, sigmoid]
- **`Dropout`**: [0.2, 0.25, 0.3]
- **`Learning rate`**: [0.001, 0.0001, 0.00001, 0.00025]
- **`Activation function in Output layer`**: [softmax, sigmoid]
- **`Loss function`**: BinaryCrossentropy
- **`Optimizer`**: [Adam, Nadam, Adamax]
- **`Batch size`**: [64, 128, 256, 512]
- **`Epoch`**: [100, 200, 300, 400, 500, 600, 800, 1,000, 1,300, 1,500, 2,000]


<img src="https://github.com/lukplamino/DADS7202_HW01_MNLP_Group/blob/main/images/Train_models.png" alt="drawing" style="width:1500px;"/>

### Re-train model from the best model (Row 8)
- **`Random state`**: 88
- **`Number of Hidden layer`**: 3
- **`Number of Units in Hidden layer`**: [32, 64, 128]
- **`Activation function in Hidden layer`**: tanh
- **`Dropout`**: 0.25
- **`Learning rate`**: 0.0001
- **`Activation function in Output layer`**: sigmoid
- **`Loss function`**: BinaryCrossentropy
- **`Optimizer`**: Adam
- **`Batch size`**: 128
- **`Epoch`**: 200

<img src="https://github.com/lukplamino/DADS7202_HW01_MNLP_Group/blob/main/images/Model_Summary.png" alt="drawing" style="width:500px;"/>

[üîù](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#highlight)

## 4. Resultsüìà
 - ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Train vs Validation (‡πÄ‡∏ä‡πà‡∏ô Loss/Accuracy)
‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏Ñ‡∏ß‡∏£‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö scale ‡∏Ñ‡πà‡∏≤‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏•‡∏∞‡∏î‡∏π underfit / overfit ‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢
 - ‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÄ‡∏™‡∏°‡∏≠‡∏ß‡πà‡∏≤‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ö‡∏ô train set ‡∏´‡∏£‡∏∑‡∏≠ val set ‡∏´‡∏£‡∏∑‡∏≠ test set 
 - ‡∏£‡∏∞‡∏ö‡∏∏‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏ß‡πâ‡πÄ‡∏™‡∏°‡∏≠ ‡πÄ‡∏ä‡πà‡∏ô ‚Äú‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á xxx‚Äù ‡∏Å‡πá‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡∏à‡∏≤‡∏Å‡πÑ‡∏´‡∏ô‡∏Å‡∏µ‡πà‡∏Ñ‡πà‡∏≤‡∏ö‡πâ‡∏≤‡∏á‡∏ô‡∏≥‡∏°‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Å‡∏±‡∏ô
 - ‡∏£‡∏∞‡∏ß‡∏±‡∏á‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÉ‡∏î ‡πÜ ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ö‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏°‡∏ï‡πà‡∏≠‡∏Ñ‡∏π‡πà‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ‡πÄ‡∏ä‡πà‡∏ô ‡∏´‡∏≤‡∏Å‡∏à‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö training time ‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏´‡∏ô‡∏°‡∏≤‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏±‡∏ô ‡∏Å‡πá‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏õ‡πá‡∏ô training 
time per one epoch (‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡πÜ epoch), ‡∏´‡∏≤‡∏Å‡∏à‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö inference time per 
one sample ‡∏Å‡πá‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏≤‡∏à‡∏≤‡∏Å test samples ‡∏ä‡∏∏‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡∏ö‡∏ô CPU ‡∏´‡∏£‡∏∑‡∏≠ GPU 
‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô, ‡∏´‡∏≤‡∏Å‡∏à‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ß‡πà‡∏≤ loss ‡∏°‡∏≤‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏±‡∏ô ‡∏Å‡πá‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì 
loss ‡∏™‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô
 - ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏Ç‡∏≠‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ mean¬±SD ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ initial random weights ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡∏ô‡πâ‡∏≠‡∏¢ 3-5 ‡∏£‡∏≠‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 3-5 ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏≤‡∏´‡∏≤‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Å‡∏±‡∏ô, ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£ train ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö train vs.validation, ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏î underfit ‡∏´‡∏£‡∏∑‡∏≠ overfit ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà, ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ evaluation metric ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô train/val/test sets ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤, ‡∏´‡∏≤‡∏Å‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏≤‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô ‡πÜ (‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ô‡∏≠‡∏∑‡πà‡∏ô) ‡∏ö‡∏ô any standard benchmark dataset ‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏à‡∏∞‡∏¢‡∏¥‡πà‡∏á‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏á‡∏≤‡∏ô‡∏î‡∏π‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâtrain ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâinference ‡∏ö‡∏ô‡∏ã‡∏µ‡∏û‡∏µ‡∏¢‡∏π‡πÅ‡∏•‡∏∞‡∏à‡∏µ‡∏û‡∏µ‡∏¢‡∏π ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏Ø‡∏•‡∏Ø
 
### Traditional Machine Learning (ML)
For training traditional machine learning, we picked **`Random Forest`**, **`Logistic Regression`**, **`Decision Tree`**, **`K Nearest Neighbor`**, and **`linear Support Vector Machine`** for trianing data to compare the results of them. We chose those models due to their simplicity and fast of training.

<img src="https://github.com/lukplamino/DADS7202_HW01_MNLP_Group/blob/main/images/Traditional_model.png" alt="drawing" style="width:500px;"/>

From the table, we can see that the **`Random Forest with Weighted Averages`** has the highest accuracy at **`75.6%`**.

### Multilayer Perceptron (MLP)



[üîù](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#highlight)


## 5. Discussionüí≠
_‡∏≠‡∏†‡∏¥‡∏õ‡∏£‡∏≤‡∏¢‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ï‡∏≤‡∏°‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ú‡∏¥‡∏î‡∏Ñ‡∏≤‡∏î ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ï‡∏≤‡∏°‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô‡∏ö‡πâ‡∏≤‡∏á, ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏ß‡πà‡∏≤‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏Ñ‡∏≤‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏ô‡∏±‡πâ‡∏ô‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏≠‡∏∞‡πÑ‡∏£, ‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà dataset ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô imalanced dataset ‡∏Ñ‡∏ß‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡πà‡∏≤‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ç‡∏≠‡∏á dataset ‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà_

[üîù](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#highlight)

## 6. Conclusionüìä
_‡∏Å‡∏≤‡∏£‡∏≠‡∏†‡∏¥‡∏õ‡∏£‡∏≤‡∏¢‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏• ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Å‡∏±‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
‡∏°‡∏¥‡πÉ‡∏ä‡πà‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡∏Ç‡πâ‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô general conclusion ‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ ‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡∏∑‡πà‡∏ô ‡πÜ 
‡πÉ‡∏ô‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï ‡∏°‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ã‡πâ‡∏≥‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏î ‡πÜ ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏Ç‡πâ‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß_

_‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡πà‡∏≤‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ç‡∏≠‡∏á dataset ‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏´‡∏•‡∏±‡∏Å (objective) ‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á_

[üîù](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#highlight)

## 7. Referencesüåê

### Library
- **`Pipeline`**
- **`SimpleImputer`**
- **`StandardScaler`**
- **`OneHotEncoder`**
- [**`ColumnTransformer`**](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html)
- **`SelectKBest`**
- **`precision_recall_fscore_support`**
- **`LogisticRegression`**
- **`SVC`**
- **`KNeighborsClassifier`**
- **`RandomForestClassifier`**

### Version
<img src="https://github.com/lukplamino/DADS7202_HW01_MNLP_Group/blob/main/images/Version.png" alt="drawing" style="width:400px;"/>

### References
- _ZHENGHAO XIAO. (2021, July 3)_
[**Classification on Categorical Data Part 1**](https://www.kaggle.com/code/iyet1killer/classification-on-categorical-data-part-1-sklearn#Model-Training): Sklearn. Kaggle. 
- _Natdanai, T., Wuthipoom, K., Nuj , L., Krisana, P., Songpol, B., Phawit, B_. (2022, February 6)
[**Powered by The Deep Sleeping Crew**](https://github.com/robinoud/BADS7604_HW3_Deep-Learning?fbclid=IwAR2dfuoK7UWRjvps-sSetnGYrIjDQ6ZzNirOOvJcstEQ30aVtTYlMeuwv0c). Github.


[üîù](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#highlight)

## Citing: 
[Bib.file](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group/blob/main/Citing_MNLP.bib)

<img src="https://github.com/lukplamino/DADS7202_HW01_MNLP_Group/blob/main/images/citing.png" alt="drawing" style="width:600px;"/>

[üîù](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#highlight)

## üë• Members, Percent Contribution and Responsibility 
|No  |ID                |Name                              |% Contribution |Responsibility                             |
|:---:|:---:             |---                               |:---:            |:---|
|1.  |**`6410422002`**  |[Navapol San.](https://www.kaggle.com/navapol)                      |   **`25%`**     |**`Explore data`** **`Prepare dataset`** **`Experiment with traditional ML`** **`Experiment with MLP `**  
|2.  |**`6410422003`**  |[Pakawut Kam.](https://www.kaggle.com/ppakawut)                     |   **`25%`**     |**`Explore data`** **`Prepare dataset`** **`Experiment with traditional ML`** **`Experiment with MLP `** |
|3.  |**`6410422024`**  |[Supisara Poo.](https://www.kaggle.com/supisarapo)                     |   **`25%`**     |**`Explore data`** **`Prepare dataset`** **`Experiment with MLP `** **`Evaluate and conclude result`**  |
|4.  |**`6410422027`**  |[Kantima Tec.](https://www.kaggle.com/kantimatec)                     |   **`25%`**     |**`Explore data`** **`Prepare dataset`** **`Experiment with traditional ML`** **`Evaluate and conclude result`** |

[üîù](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#highlight)

## üñáÔ∏èEnd Credit 
This project is a part of **`DADS7202 Deep Learning`**

Term: 1 Year of education: 2022

üéìMaster of Science Program in **`Data Analytics and Data Science`** (DADS)

üè´National Institute of Development Administration (**`NIDA`**)

<img src="https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&color=525252"/> 



[üîù](https://github.com/lukplamino/DADS7202_HW01_MNLP_Group#highlight)
